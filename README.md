# Data Cleaning:

Data Cleaning:

This notebook focuses on cleaning text data using various techniques to prepare it for analysis or natural language processing tasks. The following steps are performed:
1) Lowercasing: Convert all text to lowercase to ensure consistency and simplify processing.
2) Punctuation Removal: Remove all punctuation marks to focus on the actual words in the text.
3) Stopwords Removal: Eliminate common stopwords (e.g., "the", "is", "in") from the text as they do not contribute much to the meaning.
4) Removing Frequent Words: Identify and remove extremely frequent words that might be uninformative or common across all documents.
5) Removing Rare Words: Eliminate words that appear very rarely in the text, as they may not provide sufficient information for analysis.
6) Stemming: Reduce words to their root form using stemming to normalize variations of words.
7) Lemmatization: Convert words to their base form using lemmatization to further normalize the text.
8) Removing Emojis, Emoticons, URLs, HTML Tags: Eliminate emojis, emoticons, URLs, and HTML tags from the text to focus on the textual content.
